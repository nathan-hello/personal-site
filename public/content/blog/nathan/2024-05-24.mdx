--- 
title: Counting Chickens
author: nathan 
date: 24 May 2024 
image:
  letterman-internet.png:
    alt: "Bill Gates and David Letterman discussing the usefulness of the internet in 1995" 
---
### The tech industry can't help but count chickens 

Watch [this video](https://www.youtube.com/watch?v=fs-YpQj88ew) of Bill Gates talk with David Letterman in 1995.
Letterman wants to be sold on this whole "internet" business and, I believe, is earnestly listening. Without any
data to back this up, I think he's voicing the concerns of the unconvinced majority of Americans who constantly
hear about how the internet is going to change the world, but can't find a way to fit a computer into their daily
life. Gates makes a joke about this, that Letterman "has too many assistants" for the internet to be useful. Media
diet? Who is going to take someone seriously when they say "imagine all of the new media you're going to be able
to consume with this technology!" Has anyone at any point of time wanted more media to consume? That seems like a
weird sell, even for someone in 1995. Productivity could be a proposition, but if you're not working in something
that a computer could obviously fill a void, the demand isn't there yet.

This is where AI people find themselves now, and where crypto people were a few years ago (before everyone gave
up trying to make a use-case that doesn't exist). You simply cannot sell a dream. Bill Gates didn't convince Letterman
in that interview, and nor should he have. AI people will look at this conversation and think "How silly is David
Letterman in this video! How could he not see the future of the internet? It was 1995! It was already there, just
waiting for the likes of Amazon and Netflix to change the American economy forever!" In reality, though, that is
the only reasonable opinion. If you don't see a value add for a technology, it's not on you to "understand" it more,
it's on the technology to make it relevant to you if they want your adoption. 

AI people are stuck right now with this reality. And what's worse is that they have very little to show for their
fruits. ChatGPT is a great technology and has been incredibly useful for me personally learning all this programming
stuff. If I were to add up the amount of time the chatbot has saved by giving me good analysis on specific concepts
and tutorials, and subtract the amount of time I've wasted by investigating its hallucinations, it's undoubtedly
a net positive. My favorite thing is to have it explain "like I'm coming from Python", or something to that effect,
so its explanation is tailored to what I already know. This tool is not something that is easily replaced by reading
the documentation because of this tailoring. I got so much use out of the chatbot that I paid the $20/month since GPT-4
came out up until a couple months ago when my skill issues subsided enough that I could deal with the free tier.

I bring that up to say that I'm not an AI doubter in the sense that my friend was, who, when she learned that GPT-4 got
[a passing grade on the BAR exam](https://www.abajournal.com/web/article/latest-version-of-chatgpt-aces-the-bar-exam-with-score-in-90th-percentile),
said "So what, if I had access to the entire internet during a test I could pass it too". This is the threshold I think
some of the early AI people were trying to convince us passed. It's not just that the thing can do X provided much of
the information from the entire internet. It's that.. holy moly! We just found a way to wrangle much of the knowledge
from the internet in one program! I see a future where this is much more useful than it is now. Maybe the chatbot can
gather insights into the information that we gave it that no human would look for. Maybe the machine learning black-box
part actually makes it understand the underlying data instead of being "a very fancy auto-predict" (I hate this response
the most). Unlocking this could be huge.

Crypto is the same way. I imagine crypto people 10 years ago were yelling at their Lettermans who would say 
"What do you mean I have this digital money? I already have real money that people actually care about. 
Even if places would take this digital money, the fact that it's so volatile doesn't make
it a useful currency". After 15 years, that argument basically won. After the NFT boom and bust, crypto is no where to 
be found except for places where you don't want big man watching. 
Here's the crypto sell I say to the Lettermans in my life: It's not about money, or
about randomly generated pictures of monkeys, it's about the fact that we figured out how to have
scarcity *exist* on the internet. Without crypto, any 1's and 0's you send can be infinitely replicated or transformed
and there's no sense of ownership except [by the legal system](https://www.youtube.com/watch?v=C6aeL83z_9Y). With crypto,
there is now a concept of digital ownership. Is that useful? Could the title to your house be put on the blockchain to circumvent the banking system with
their fees and monopoly on accreditation? We don't know, we've looked far and wide and it hasn't worked out to be useful enough for
adoption in any public setting. But, it's cool.

As I said, no one is trying to sell crypto anymore. The hype is gone, the refs have decided it's a bust. No hope in
the foreseeable future except if bitcoin hits 6 digits and the eighth round of scam artists come out of the woodworks.
I don't think there's any way that AI will fulfill its lofty promises. OpenAI has one really good product. One product,
a new internet does not make. We've gotten so used to platforms and opaque software that we seem to have forgotten that
the internet was built on so much ridiculously open-source software it would make Sam Altman of "Open"AI's head spin.
The industry has forgotten this fact and it's very sad. I have no problem with a company making software, not
open-sourcing it, and making a butt load of money off of it. Pop off, make your bag, have fun. But if you're trying to
enter the next era of computing off of something as proprietary as Facebook or Fortnite, it's not going to work. 

(speaking of, if anyone has some
insights on why open-source never made its way into gaming related software until things like Godot, please leave a comment). 

Not only do these LLMs not have standards to be graded off of, you kind of can't! They aren't deterministic, it is
impossible to get the same output with the same input. They are rushing to build a new internet and they have no
idea what it is. They are trying to sell Letterman, but when Letterman asks "But what is it really?", they give
wild speculation that requires technology that doesn't exist yet. "But we've come so far in just a few years, surely
we'll catch up to our self-imposed expectations!" Why set them in the first place? Why are you doing this to yourselves?
I thought VC money was expensive these days. They rushing to push LLMs to Lettermans but this time, there is no value.
There is an annoying pop-up on Google that brings down the results of your search with LLM garbage. Every time I've seen
an "AI Overview" on Google, it is bare minimum worse than the first link. And how could it not? Automatically running a
GPT-3.5-quality query on some significant number of Google searches would be so much compute. Maybe they have enough hardware,
but then it's an energy question. Those LLM queries aren't cheap compared to a typical search. You might notice the lack
of graphs and statistics, but I don't see how I'm wrong. All I'll say is that they either 100x the quality of their LLMs,
or they will recoil in embarrassment, subject to clowning for the next decade on how awful this era of Google is.

Would Google search be better as a conversation? Again,
no statistics, but some huge percentage of Google searches are not complicated enough for an LLM to be useful. If I want to order
takeout, go to my movie theater's website, go out and do anything planning, I Google the company. Most times, I could have just gone
to "texasroadhouse.com", but instead of taking the risk of going to a domain squatter who takes advantage of this naivete, I'll Google
it and click on the top link. And sometimes I'll do this even for websites that I've visited a hundred times. A Google search is
so cheap in my mind that it's not a problem to do an extra two clicks for a guarantee of correctness. The Gates of the world
might say "Well you're *used* to using Google in that way because of its limited functionality, when it can do more you
will do more with it". And I agree! Like I said, I paid OpenAI $20/month for around a year, I'm well aware of the potential
value add... for complicated questions that require a chat experience. These AI Overviews shouldn't be in Google by default 
because most of the time I don't want an overview - I want a resource. And there's no amount of algorithm shenanigans that will 
be able to infer what I want. I don't go to ChatGPT for the height of the Empire State because it's not the right tool for the
job. Google should have a separate area that doesn't distract from links for this task. I imagine Google Bard is a good chatbot,
I haven't tried it out because I doubt its free tier is better than GPT-3.5, but that's the appropiate area for a chatbot to exist.
It's own space. I'm not sure how Bing settled this. Did they distract from their links with AI stuff? Did it make a chatbot query
and interrupted the results with whatever it said? I'm not sure, I never used Bing in a serious enough way, even after the initial hype, 
to remember.


The first question (put last in this rambly post) is "Do we want this in the most idealized form?" Not to be a Letterman,
but I can't understand how talking to a computer in natural language is going to be better than what we've devised in the
last 40 years of user interface design. Obviously I won't use a chatbot to interface with my computer, I like the least amount of 
things in between me and what I want my computer to do as possible. But take someone who wants to not manage their windows, not manage
settings, their filesystem, they just want their computer to work. Maybe they use their computer in the bare-minimum case: content consumption.
Would consuming content be better without using a mouse or keyboard? How would you correct errors from the AI? Talk to it again?
What about when the AI understood what you said, but not what you meant? And mind you, these aren't searches for internet content, 
this is basic manipulation of your computer. These keyboards are faster than speaking because they are buttons! Real deal, tactile,
do-something-instantly buttons! Does anyone walk around with laptops where the keyboard is a touch screen like your phone is? No!
Because that's awful! Do people who write for a living do so with a voice-to-text prompt? No! Even if they had an editor by their
side helping the computerized scribe correct errors, the writer would still be frustrated because they now have something in between
what they want to do and what they are doing. It's an unnecessary complication. Unless of course, it is necessary. Accessibility could
be a big win for AI - from transcribing poorly written websites & software into something that you can understand, or by being
exactly what Sam Altman wants everyone to do in talking to their computers in natural language. That would be a great win for
these people! But no, we aren't satisfied with an incredibly complicated LLM like GPT-4 that makes bajillion dollars a year,
or for finally making most software accessible to people who have been overlooked by developers, or with giving people links
to the resources they were asking for. We have to make a new internet, off of a platform that no one understands, no outsiders
can contribute to, and [without a faint definition of what data comprises these LLMs](https://twitter.com/tsarnick/status/1768021821595726254).  

This was my AI rant, hopefully I have expressed enough opinions to either eat them in 5 years or be a vindicated gigabrain.

Footnote ramble:

A month and no post. Not the best. I've been busy! I have a new job situation that I've had to spend a lot more
time at than I've been used to, I've been working on my side projects, and I'm just simply afraid getting out of
my step with writing compounds itself. No more! A post, to get back into things.

A question: Why does everyone hate their neighbors?

It's something I've noticed, where, in a large organization, people don't like the other shifts when talking
among their shift. And if they are talking to the other shift, well they don't like the people that work
in the other office. And if they're talking to the people in the other office, then they don't like the
people in the other building. "Why would someone write this document this way? It's horrendous!" a worker says to their roaring companions.
Then, the next day, when the author is in the room to explain themselves, it's all "Oh, right yeah I'm sure there
was something about that", apologies, and "no problem"s flying around. It's insincere, and it makes me question
whether my friends say the same thing about my when I change shifts, or offices, or buildings.

Hey Natalie, this was a lot of fun to write. Please don't let me wait another month to write again :)
